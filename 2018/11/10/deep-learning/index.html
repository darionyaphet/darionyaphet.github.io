<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="science &amp; art"><title>deep-learning | Hexo</title><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/font.css"><link rel="stylesheet" type="text/css" href="/css/noise.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a><a class="sidebar-nav-item" href="/archives">Archives</a></nav><div class="container post-meta"><div class="post-tags"><a class="post-tag-link" href="/tags/deep-learning/">deep learning</a></div><div class="post-time">2018-11-10</div></div></div><div class="container post-header"><h1>deep-learning</h1></div><div class="container post-content"><p><strong>MNIST 数据集</strong></p>
<p><code>MNIST</code> 数据集经常被用来检验机器学习模型的性能，<a href="http://yann.lecun.com/exdb/mnist" target="_blank" rel="noopener">官网</a>包含多达68 种模型在该数据集上的准确率数据，包括线性分类器， K近邻方法 、普通的神经网络、卷积神经网络等。</p>
<p><code>tf.Tensor</code> 类是 <code>TensorFlow</code> 的核心类，常用的<code>占位符</code>（ tf.placeholder ）、<code>变量</code>（ tf.Variable）都可以看作特殊的 <code>Tensor</code>。</p>
<hr>
<p><strong>词向量</strong></p>
<hr>
<p><strong>19种损失函数</strong></p>
<blockquote>
<p>L1范数损失 L1Loss</p>
<blockquote>
<p>计算 output 和 target 之差的绝对值。</p>
</blockquote>
</blockquote>
<blockquote>
<p>均方误差损失 MSELoss</p>
<blockquote>
<p>计算 output 和 target 之差的均方差。</p>
</blockquote>
</blockquote>
<blockquote>
<p>交叉熵损失 CrossEntropyLoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>KL 散度损失 KLDivLoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>二进制交叉熵损失 BCELoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>BCEWithLogitsLoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>MarginRankingLoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>HingeEmbeddingLoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>多标签分类损失 MultiLabelMarginLoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>平滑版L1损失 SmoothL1Loss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>2分类的logistic损失 SoftMarginLoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>多标签 one-versus-all 损失 MultiLabelSoftMarginLoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>cosine 损失 CosineEmbeddingLoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>多类别分类的hinge损失 MultiMarginLoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>三元组损失 TripletMarginLoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>连接时序分类损失 CTCLoss   </p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>负对数似然损失 NLLLoss</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>NLLLoss2d</p>
<blockquote>
</blockquote>
</blockquote>
<blockquote>
<p>PoissonNLLLoss</p>
<blockquote>
</blockquote>
</blockquote>
<hr>
<p>Reference:</p>
<ol>
<li><a href="http://licstar.net/archives/328#s0" target="_blank" rel="noopener">Deep Learning in NLP （一）词向量和语言模型</a></li>
<li><a href="https://mp.weixin.qq.com/s/4qTBfZ7k2OMjtFNiPSUFaQ" target="_blank" rel="noopener">十九种损失函数，你认识几个？</a></li>
</ol>
</div></div><div class="post-main post-comment"></div></article><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
  $(".fancybox").fancybox();
});
</script></body></html>